# YouTube Audio RAG Pipeline

This project was developed as an assignment for the Data Engineering Bootcamp (May 2025) at https://www.dataexpert.io/.
This repository provides a **very simple**, easy-to-understand example to quickly implement a Retrieval-Augmented Generation (RAG) solution that lets you ask questions and search over video content. It is designed for rapid experimentation and learning.

**Note:**
- This pipeline is intended for videos generally under **20 minutes** in length.
- The extracted MP3 audio files should not exceed **25 MB** in size.
- When using this pipeline in your own context, be sure to adjust the `CATEGORIES` list in `src/categories.py` to match the domain and content of your videos.

---

## Prerequisites

1. **Python 3.8 or higher** installed  
2. **Git** (optional, to clone the repository)  
3. **API keys** for:  
   - OpenAI (for Whisper transcription and embeddings)  
   - Pinecone (for your vector database)  
4. **ffmpeg** installed and on your system PATH  

---

## Installation and Setup

1. **Clone the repository** (or download the ZIP and unpack)

   ```bash
   git clone https://github.com/charlysegovia/youtube_audio_rag_pipeline.git
   cd youtube_audio_rag_pipeline
   ```

2. **Create a Python virtual environment**

   - On Windows (Git Bash or PowerShell):
     ```bash
     python -m venv .venv
     ```
   - On macOS or Linux:
     ```bash
     python3 -m venv .venv
     ```

3. **Activate the virtual environment**

   - On Git Bash or macOS/Linux:
     ```bash
     source .venv/Scripts/activate    # on Windows Git Bash
     source .venv/bin/activate        # on macOS/Linux
     ```
   - On PowerShell (Windows):
     ```powershell
     .venv\Scripts\Activate.ps1
     ```

4. **Upgrade pip and install dependencies**

   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

5. **Create a `.env` file** in the project root with these entries (no quotes):

   ```
   OPENAI_API_KEY=sk-...
   PINECONE_API_KEY=your_pinecone_api_key
   FLASK_HOST=0.0.0.0
   FLASK_PORT=3001
   FLASK_DEBUG=true
   ```

   Replace `sk-...` and the other values with your actual keys and desired settings.

---

## Project Structure

```
youtube_audio_rag_pipeline/
├── .env
├── .gitignore
├── README.md
├── requirements.txt
├── logs/                    ← log files are written here
├── videos/                  ← downloaded and transcoded videos
├── audio/                   ← extracted audio files and transcripts
└── src/
    ├── config.py            ← loads .env and holds configuration
    ├── downloader.py        ← downloads video and transcodes audio to AAC
    ├── audio_extractor.py   ← extracts and converts audio to mp3 or wav
    ├── transcriber.py       ← calls OpenAI Whisper for transcription
    ├── chunker.py           ← splits transcript into token-based chunks
    ├── embedder.py          ← generates embeddings for each chunk
    ├── pinecone_uploader.py ← uploads vectors to Pinecone with metadata
    ├── categories.py        ← classifies each chunk into data engineering categories
    ├── logger.py            ← configures logging to console and file
    ├── server.py            ← Flask web application (`/process` and `/ask`)
    └── main.py              ← CLI script to run the full pipeline
```

---

## Command-Line Usage

1. Ensure the virtual environment is activated and `.env` is configured.  
2. Run the pipeline with:

   ```bash
   python src/main.py <YouTube_URL> <Pinecone_Index_Name>
   ```

   Example:

   ```bash
   python src/main.py https://www.youtube.com/watch?v=wPrxJPZefhI my-index
   ```

3. The script will print each step to the console and will:

   - Save the video in `videos/`
   - Save the extracted audio in `audio/` as MP3
   - Save the transcript in `audio/*.txt`
   - Upload embeddings to the specified Pinecone index

---

## Web UI Usage

1. Start the Flask server:

   ```bash
   python src/server.py
   ```

2. Open your browser to `http://localhost:3001/process`  
   - Enter the YouTube video URL  
   - Select the Pinecone index from the dropdown  
   - Click **Run Pipeline**  
   - Watch the step-by-step status updates on the page  

3. To ask questions against the indexed content, go to `http://localhost:3001/ask`  
   - Enter your query  
   - Select the same Pinecone index  
   - Click **Submit**  
   - The answer, generated by ChatGPT using your indexed chunks, will appear below

---

## Recreate Your Pinecone Index Manually

1. Log in to your Pinecone console at https://app.pinecone.io.  
2. In the **Indexes** list, find your index (e.g. `hw5`) and click the three-dot menu next to it.  
3. Select **Delete Index**, confirm the deletion.  
4. Click **Create Index**.  
   - **Name**: enter the same index name (e.g. `hw5`)  
   - **Dimension**: set to `3072`  
   - **Metric**: choose `cosine`  
   - **Environment**: pick your Pinecone environment (e.g. `us-west1-gcp`)  
5. Click **Create**.  

Your index will now be empty and configured for 3072-dimensional vectors, matching the embedding model.

---

## Notes

- Make sure the embedding model you choose matches your Pinecone index dimension.  
- Check `logs/pipeline.log` for a complete, timestamped record of each run.  
